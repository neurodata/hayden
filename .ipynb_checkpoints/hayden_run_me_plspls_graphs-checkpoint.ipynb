{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from graspy.simulations import er_np, sbm\n",
    "from graspy.embed import AdjacencySpectralEmbed\n",
    "from graspy.inference import LatentDistributionTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_avantis_plug_in(X):\n",
    "    '''\n",
    "    Estimates the variance using the plug-in estimator.\n",
    "    RDPG Survey, equation 10.\n",
    "    '''\n",
    "    n = len(X.T)\n",
    "    delta = 1 / (n) * (X @ X.T)\n",
    "    delta_inverse = np.linalg.inv(delta)\n",
    "    \n",
    "    def avantis_plug_in(x):\n",
    "        if x.ndim < 2:\n",
    "            undo_dimensions = True\n",
    "            x = x.reshape(-1, 1)\n",
    "        else: \n",
    "            undo_dimensions = False\n",
    "        middle_term = np.sum(x.T @ X - (x.T @ X)**2, axis=1) / (n)\n",
    "        middle_term = np.outer(middle_term, delta)\n",
    "        if undo_dimensions:\n",
    "            middle_term = middle_term.reshape(delta.shape)\n",
    "        else:\n",
    "            middle_term = middle_term.reshape(-1, *delta.shape)\n",
    "        return delta_inverse @ middle_term @ delta_inverse\n",
    "    \n",
    "    return avantis_plug_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noisy_points(X, Y):\n",
    "    n = len(X.T)\n",
    "    m = len(Y.T)\n",
    "    two_samples = np.concatenate([X, Y], axis=1)\n",
    "    get_sigma = fit_avantis_plug_in(two_samples)\n",
    "    sigma_X = get_sigma(X) / m\n",
    "    sigma_Y = get_sigma(Y) / n\n",
    "    X_sampled = np.zeros(X.shape)\n",
    "    for i in range(n):\n",
    "        X_sampled[:,i] = X[:, i] + stats.multivariate_normal.rvs(cov=sigma_X[i]).T\n",
    "    Y_sampled = np.zeros(Y.shape)\n",
    "    for i in range(m):\n",
    "        Y_sampled[:,i] = Y[:, i] + stats.multivariate_normal.rvs(cov=sigma_Y[i]).T\n",
    "    return X_sampled, Y_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_iter(n, m, p, q, tilde, i=1):\n",
    "    X_graph = er_np(n, p)\n",
    "    ase = AdjacencySpectralEmbed(n_components=1)\n",
    "    X = ase.fit_transform(X_graph).T\n",
    "\n",
    "    Y_graph = er_np(m, q)\n",
    "    ase = AdjacencySpectralEmbed(n_components=1)\n",
    "    Y = ase.fit_transform(Y_graph).T\n",
    "\n",
    "    if tilde:\n",
    "        X_new, Y_new = sample_noisy_points(X, Y)\n",
    "    else:\n",
    "        X_new, Y_new = X, Y\n",
    "\n",
    "    ldt = LatentDistributionTest()\n",
    "    pval = ldt.fit(X_new.T, Y_new.T, pass_graph=False)#, median_heuristic=False)\n",
    "    return pval\n",
    "\n",
    "def mc_iter_wrapper(i, n, m, p, q, tilde):\n",
    "    np.random.seed(int(time.time() * i) % 100000000)\n",
    "    return i, mc_iter(n, m, p, q, tilde, i)\n",
    "\n",
    "def monte_carlo(n, m, p, q, tilde=False, mc_iters=200):\n",
    "    pool = Pool(cpu_count() - 2)\n",
    "    pvals = np.zeros(mc_iters)\n",
    "    \n",
    "    pbar = tqdm(total=mc_iters)\n",
    "    def update(tup):\n",
    "        i, ans = tup\n",
    "        pvals[i] = ans  # put answer into correct index of result list\n",
    "        pbar.update()\n",
    "    \n",
    "    results = [None] * mc_iters\n",
    "    for i in range(mc_iters):\n",
    "        results[i] = pool.apply_async(mc_iter_wrapper,\n",
    "                         args = (i, n, m, p, q, tilde),\n",
    "                         callback=update)\n",
    "    for r in results:\n",
    "        r.get()\n",
    "        \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    pbar.close()\n",
    "\n",
    "    return np.array(pvals) < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_iters = 200\n",
    "ns = [25, 50, 100, 200, 400, 800]\n",
    "cs= [1,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for c in cs:\n",
    "    print('current c: {}'.format(c))\n",
    "    tests_size_er_xhat = [monte_carlo(n=i, m=c*i, p=0.8*0.8, q=0.8*0.8,\n",
    "                                      mc_iters=mc_iters, tilde=False)\n",
    "                          for i in ns]\n",
    "    size_er_xhat = np.array([np.sum(i)/mc_iters for i in tests_size_er_xhat])\n",
    "    tests_size_er_xtilde = [monte_carlo(n=i, m=c*i, p=0.8*0.8, q=0.8*0.8,\n",
    "                                        mc_iters=mc_iters, tilde=True)\n",
    "                            for i in ns]\n",
    "    size_er_xtilde = np.array([np.sum(i)/mc_iters for i in tests_size_er_xtilde])\n",
    "    data[c] = (size_er_xhat, size_er_xtilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(data, open( \"nonpar_results_graphs.pkl\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
