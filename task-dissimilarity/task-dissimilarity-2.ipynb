{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "from sklearn.ensemble.forest import _generate_sample_indices\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_rotation(theta=0, acorn=None):\n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "    \n",
    "    R = np.array([\n",
    "        [np.cos(theta), np.sin(theta)],\n",
    "        [-np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def generate_parity(n, d=2, angle_params=None, acorn=None):\n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    X = np.random.uniform(-2, 2, size=(10*n, d))\n",
    "    Y = (np.sum(X > 0, axis=1) % 2 == 0).astype(int)\n",
    "    \n",
    "    if d == 2:\n",
    "        if angle_params is None:\n",
    "            angle_params = np.random.uniform(0, 2*np.pi)\n",
    "        R = generate_2d_rotation(angle_params)\n",
    "        X = X @ R\n",
    "        inds = (abs(X[:, 0]) < 1) + (abs(X[:, 1]) < 1)\n",
    "        Y = Y[(abs(X[:, 0]) < 1) * (abs(X[:, 1]) < 1)][:n]\n",
    "        X = X[(abs(X[:, 0]) < 1) * (abs(X[:, 1]) < 1)][:n]\n",
    "    return X, Y.astype(int)\n",
    "\n",
    "def generate_gaussian_parity(n, mean=np.array([-1, -1]), cov_scale=1, angle_params=None, k=1, acorn=None):\n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    d = len(mean)\n",
    "    \n",
    "    if mean[0] == -1 and mean[1] == -1:\n",
    "        mean = mean + 1 / 2**k\n",
    "    \n",
    "    mnt = np.random.multinomial(n, 1/(4**k) * np.ones(4**k))\n",
    "    cumsum = np.cumsum(mnt)\n",
    "    cumsum = np.concatenate(([0], cumsum))\n",
    "    \n",
    "    Y = np.zeros(n)\n",
    "    X = np.zeros((n, d))\n",
    "    \n",
    "\n",
    "    for i in range(2**k):\n",
    "        for j in range(2**k):\n",
    "            if cov_scale == 0:\n",
    "                temp = np.random.uniform(-1, -1 + 1/2**(k-1), size=(mnt[i*(2**k) + j], d))\n",
    "            else:\n",
    "                temp = np.random.multivariate_normal(mean, cov_scale * np.eye(d), \n",
    "                                                     size=mnt[i*(2**k) + j])\n",
    "            temp[:, 0] += i*(1/2**(k-1))\n",
    "            temp[:, 1] += j*(1/2**(k-1))\n",
    "\n",
    "            X[cumsum[i*(2**k) + j]:cumsum[i*(2**k) + j + 1]] = temp\n",
    "            \n",
    "            if i % 2 == j % 2:\n",
    "                Y[cumsum[i*(2**k) + j]:cumsum[i*(2**k) + j + 1]] = 0\n",
    "            else:\n",
    "                Y[cumsum[i*(2**k) + j]:cumsum[i*(2**k) + j + 1]] = 1\n",
    "                \n",
    "    if d == 2:\n",
    "        if angle_params is None:\n",
    "            angle_params = np.random.uniform(0, 2*np.pi)\n",
    "        \n",
    "        R = generate_2d_rotation(angle_params)\n",
    "        X = X @ R\n",
    "        \n",
    "#         Y = Y[(abs(X[:, 0]) < 1) * (abs(X[:, 1]) < 1)][:n]\n",
    "#         X = X[(abs(X[:, 0]) < 1) * (abs(X[:, 1]) < 1)][:n]\n",
    "    else:\n",
    "        raise ValueError('d=%i not implemented!'%(d))\n",
    "       \n",
    "    return X, Y.astype(int)\n",
    "\n",
    "def get_colors(colors, inds):\n",
    "    c = [colors[i] for i in inds]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_posteriors(tree, X, y):\n",
    "    n = X.shape[0]\n",
    "    size = len(np.unique(y))\n",
    "\n",
    "#     def worker(tree):\n",
    "        # Count the occurences of each class in each leaf node,\n",
    "        # by first extracting the leaves.\n",
    "        # node_counts = tree.tree_.n_node_samples\n",
    "    unique_leaf_nodes = get_leaves(tree)\n",
    "\n",
    "    class_counts_per_leaf = np.zeros(\n",
    "        (len(unique_leaf_nodes), size)\n",
    "    )\n",
    "\n",
    "    # Drop each estimation example down the tree, and record its 'y' value.\n",
    "    for i in range(len(y)):\n",
    "        temp_node = tree.apply(X[i].reshape((1, -1))).item()\n",
    "        class_counts_per_leaf[\n",
    "            np.where(unique_leaf_nodes == temp_node)[0][0], y[i]\n",
    "        ] += 1\n",
    "\n",
    "    # Count the number of data points in each leaf in.\n",
    "    n_per_leaf = class_counts_per_leaf.sum(axis=1)\n",
    "    n_per_leaf[n_per_leaf == 0] = 1  # Avoid divide by zero.\n",
    "\n",
    "    # Posterior probability distributions in each leaf.\n",
    "    # Each row is length num_classes.\n",
    "    posterior_per_leaf = np.divide(\n",
    "        class_counts_per_leaf,\n",
    "        np.repeat(n_per_leaf.reshape((-1, 1)), size, axis=1),\n",
    "    )\n",
    "    posterior_per_leaf = finite_sample_correction(\n",
    "        posterior_per_leaf, n_per_leaf\n",
    "    )\n",
    "    posterior_per_leaf = posterior_per_leaf.tolist()\n",
    "\n",
    "\n",
    "#         return (posterior_per_leaf, tree, unique_leaf_nodes)\n",
    "\n",
    "#     if parallel:\n",
    "#         uncertainty_per_tree = Parallel(n_jobs=-2)(\n",
    "#             delayed(worker)(idx_tree) for idx_tree in enumerate(forest)\n",
    "#         )\n",
    "#     else:\n",
    "#         uncertainty_per_tree = []\n",
    "#         for idx_tree in enumerate(forest):\n",
    "#             uncertainty_per_tree.append(worker(idx_tree))\n",
    "\n",
    "#     posterior_info = []\n",
    "#     for elem in uncertainty_per_tree:\n",
    "#         posterior_info.append(elem[0:3])\n",
    "\n",
    "    return posterior_per_leaf, tree, unique_leaf_nodes\n",
    "\n",
    "\n",
    "def predict(posterior_info, X):\n",
    "    \n",
    "    posterior_per_leaf = posterior_info[0]\n",
    "    tree = posterior_info[1]\n",
    "    unique_leaf_nodes = posterior_info[2]\n",
    "\n",
    "        # Posterior probability for each element of the evaluation set.\n",
    "    eval_posteriors = np.array(\n",
    "        [\n",
    "        posterior_per_leaf[np.where(unique_leaf_nodes == node)[0][0]]\n",
    "        for node in tree.apply(X)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return np.argmax(eval_posteriors, axis=1)\n",
    "\n",
    "\n",
    "def get_leaves(estimator):\n",
    "    \"\"\"\n",
    "    Internal function to get leaf node ids of estimator.\n",
    "\n",
    "    Input\n",
    "    estimator: a fit DecisionTreeClassifier\n",
    "\n",
    "    Return\n",
    "    leaf_ids: numpy array; an array of leaf node ids\n",
    "\n",
    "    Usage\n",
    "    _estimate_posteriors(..)\n",
    "    \"\"\"\n",
    "\n",
    "    # adapted from https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "    n_nodes = estimator.tree_.node_count\n",
    "    children_left = estimator.tree_.children_left\n",
    "    children_right = estimator.tree_.children_right\n",
    "    feature = estimator.tree_.feature\n",
    "    threshold = estimator.tree_.threshold\n",
    "\n",
    "    leaf_ids = []\n",
    "    stack = [(0, -1)] \n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            leaf_ids.append(node_id)\n",
    "\n",
    "    return np.array(leaf_ids)\n",
    "    \n",
    "    \n",
    "def finite_sample_correction(class_probs, row_sums):\n",
    "    \"\"\"\n",
    "    An internal function for finite sample correction of posterior estimation.\n",
    "\n",
    "    Input\n",
    "    class_probs: numpy array; array of posteriors to correct\n",
    "    row_sums: numpy array; array of partition counts\n",
    "\n",
    "    Output\n",
    "    class_probs: numpy array; finite sample corrected posteriors\n",
    "\n",
    "    Usage\n",
    "    _estimate_posteriors(..)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    where_0 = np.argwhere(class_probs == 0)\n",
    "    for elem in where_0:\n",
    "        class_probs[elem[0], elem[1]] = 1 / (2 * row_sums[elem[0], None])\n",
    "    where_1 = np.argwhere(class_probs == 1)\n",
    "    for elem in where_1:\n",
    "        class_probs[elem[0], elem[1]] = 1 - 1 / (2 * row_sums[elem[0], None])\n",
    "\n",
    "    return class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True, False,  True, False,  True,\n",
       "       False, False,  True,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False,  True,  True, False,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = generate_gaussian_parity(200)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2).fit(X, y)\n",
    "eta = estimate_posteriors(tree, X, y)\n",
    "predict(eta, X) == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_similarity_estimation_experiment(nx, funcx, paramsx, classifierx, classifier_paramsx,\n",
    "                                          nz, funcz, paramsz, classifierz, classifier_paramsz,\n",
    "                                          acorn=None):\n",
    "    \n",
    "    if acorn is None:\n",
    "        np.random.seed(acorn)\n",
    "                \n",
    "    Tx = 1\n",
    "    Tz = 1\n",
    "\n",
    "    shuffle = np.random.choice(nx, nx, replace=False)\n",
    "\n",
    "    # 60 / 20 / 20\n",
    "    transform_idx = shuffle[:int(0.6*nx)]\n",
    "\n",
    "    not_transform_idx = shuffle[int(0.6*nx):]\n",
    "    vote_idx = shuffle[int(0.6*nx): int(0.8*nx)]\n",
    "    valid_idx = shuffle[:nx - int(0.8*nx)]\n",
    "\n",
    "    # Source task\n",
    "    X, y = funcx(nx, *paramsx)\n",
    "\n",
    "    # Target task\n",
    "    Z, w = funcz(nz, *paramsz)\n",
    "\n",
    "    task1_tree = classifierx(**classifier_paramsx)\n",
    "    task1_tree.fit(X, y)\n",
    "    task1_posteriors = estimate_posteriors(task1_tree, X, y)\n",
    "    yhat1 = predict(task1_posteriors, X) \n",
    "\n",
    "\n",
    "    task2_tree = classifierz(**classifier_paramsz)\n",
    "    task2_tree.fit(Z, w)\n",
    "    task2_posteriors = estimate_posteriors(task2_tree, X, y)\n",
    "    yhat2 = predict(task2_posteriors, X)\n",
    "    \n",
    "    return np.mean(yhat1 == yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = {'xor': {\n",
    "                'funcx':generate_gaussian_parity, \n",
    "                'paramsx': (np.array([-1, -1]), 0.1, 0, 1),\n",
    "                'classifierx': DecisionTreeClassifier,\n",
    "                'classifier_paramsx': {},\n",
    "                },\n",
    "         'n-xor':{'funcx':generate_gaussian_parity, \n",
    "                'paramsx': (np.array([-1, -1]), 0.1, np.pi/2, 1),\n",
    "                'classifierx': DecisionTreeClassifier,\n",
    "                'classifier_paramsx': {},\n",
    "                },\n",
    "             \n",
    "         'r-xor':{'funcx':generate_gaussian_parity, \n",
    "                'paramsx': (np.array([-1, -1]), 0.1, np.pi/4, 1),\n",
    "                'classifierx': DecisionTreeClassifier,\n",
    "                'classifier_paramsx': {},\n",
    "                },\n",
    "         'f-xor':{'funcx':generate_gaussian_parity, \n",
    "                'paramsx': (np.array([-1, -1]), 0.01, 0, 2),\n",
    "                'classifierx': DecisionTreeClassifier,\n",
    "                'classifier_paramsx': {},\n",
    "                },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-346-8553b5de2165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                                             )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtemp_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/hh/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/hh/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/hh/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "ns = np.array([10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000])\n",
    "means = np.zeros((len(dists), len(dists), len(ns)))\n",
    "std_errors = np.zeros((len(dists), len(dists), len(ns)))\n",
    "\n",
    "n_mc=100\n",
    "for i, n in enumerate(ns):\n",
    "    for j, key1 in enumerate(dists):\n",
    "        temp = np.zeros(mc_its)\n",
    "\n",
    "        for k, key2 in enumerate(dists):\n",
    "            condensed_func = lambda x : task_similarity_estimation_experiment(x, \n",
    "                                                                              dists[key1]['funcx'],\n",
    "                                                                              dists[key1]['paramsx'],\n",
    "                                                                              dists[key1]['classifierx'],\n",
    "                                                                              dists[key1]['classifier_paramsx'],\n",
    "                                                                              n,\n",
    "                                                                              dists[key2]['funcx'],\n",
    "                                                                              dists[key2]['paramsx'],\n",
    "                                                                              dists[key2]['classifierx'],\n",
    "                                                                              dists[key2]['classifier_paramsx']\n",
    "                                                                            )\n",
    "                                                                              \n",
    "            temp_errors = np.array(Parallel(n_jobs=-2)(delayed(condensed_func)(int(x)) for x in n*np.ones(n_mc)))\n",
    "            \n",
    "            means[j,k,i] = np.mean(temp_errors)\n",
    "            std_errors[j,k,i] = np.std(temp_erorrs) / np.sqrt(n_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx=1000\n",
    "funcx=generate_gaussian_parity\n",
    "paramsx= (np.array([-1, -1]), 0.05, 0, 1)\n",
    "classifierx=DecisionTreeClassifier\n",
    "classifier_paramsx={}\n",
    "\n",
    "nz=1000\n",
    "funcz=generate_gaussian_parity \n",
    "paramsz=(np.array([-1, -1]), 0.05, 0, 2)\n",
    "classifierz=DecisionTreeClassifier\n",
    "classifier_paramsz={}\n",
    "                       \n",
    "task_similarity_estimation_experiment(nx, funcx, paramsx, classifierx, classifier_paramsx, \n",
    "                                      nz, funcz, paramsz, classifierz, classifier_paramsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_similarity_estimation_experiment(nz, funcz, paramsz, classifierz, classifier_paramsz, \n",
    "                                      nx, funcx, paramsx, classifierx, classifier_paramsx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh",
   "language": "python",
   "name": "hh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
