{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graspy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import os\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_distance(dist_matrix, S_indices, model_name=None, return_new_dists=True):\n",
    "    \"\"\"\n",
    "    A function to find the weights of optimal linear combination of distances.\n",
    "    \n",
    "    Input\n",
    "    dist_matrix - np.array (shape=(n, J))\n",
    "        Array containing the distances between the vertex of interest and the other n - 1\n",
    "        vertices. It is assumed that the vertex of interest is indexed by 0.\n",
    "    S_indices - array-like\n",
    "        Array-like containing the indices of the vertices that should be at the top of the\n",
    "        nomination list for the vertex of interest.\n",
    "        \n",
    "    Return\n",
    "    weights - np.array (length=J)\n",
    "        Array containing the coefficients for the optimal distance function.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, J = dist_matrix.shape\n",
    "    M = np.sum(abs(dist_matrix))\n",
    "    \n",
    "    S = len(S_indices)\n",
    "    Q_indices = np.array([i for i in range(1, n) if i not in S_indices])\n",
    "    Q = len(Q_indices)\n",
    "    \n",
    "    M = np.sum(abs(dist_matrix))\n",
    "    \n",
    "    if model_name is not None:\n",
    "        m = gp.Model(name='%s'%(model_name))\n",
    "    else:\n",
    "        m= gp.Model()\n",
    "        \n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    ind = m.addVars(Q, vtype=GRB.BINARY, name='ind')\n",
    "    m.setObjective(gp.quicksum(ind), GRB.MINIMIZE)\n",
    "\n",
    "    w = m.addVars(J, lb=0, ub=1, vtype=GRB.CONTINUOUS, name='w')\n",
    "    m.addConstr(w.sum() == 1)\n",
    "\n",
    "    # There's likely a more pythonic way to set up these constraints (in particular using m.addConstrs(..))\n",
    "    for s in S_indices:\n",
    "        temp_s = gp.tupledict([((i), dist_matrix[s, i]) for i in range(J)])\n",
    "        for i, q in enumerate(Q_indices):\n",
    "            temp_q = gp.tupledict([((i), dist_matrix[q, i]) for i in range(J)])\n",
    "            m.addConstr(w.prod(temp_s) <= w.prod(temp_q) + ind[i]*M)\n",
    "        \n",
    "    m.optimize()\n",
    "    \n",
    "    alpha_hat = np.array([i.X for i in list(w.values())])\n",
    "    \n",
    "    if model_name:\n",
    "        m.write('%s.ip'%(model_name))\n",
    "        \n",
    "    if return_new_dists:\n",
    "        return alpha_hat, np.average(dist_matrix, axis=1, weights=alpha_hat)\n",
    "    \n",
    "    return alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         SourceProduct       SimilarProduct  Tier\n",
      "0      Apple iPhone XR  Apple iPhone Xs Max     1\n",
      "1      Apple iPhone XR       Apple iPhone X     1\n",
      "2      Apple iPhone XR      Apple iPhone XS     1\n",
      "3  Apple iPhone Xs Max       Apple iPhone X     1\n",
      "4  Apple iPhone Xs Max      Apple iPhone XS     1\n",
      "{'Apple iPhone XR': [75, 171, 135], 'Apple iPhone Xs Max': [171, 135, 100], 'Apple iPhone 11': [432, 341], 'Samsung Galaxy S10': [234, 62, 107, 187], 'Nikon D7200': [566, 271], 'Microsoft Surface Laptop': [1439, 1231]}\n"
     ]
    }
   ],
   "source": [
    "all_S_csv = pd.read_csv('ProductSimilarities.csv')\n",
    "nodes = pd.read_csv('jhu_package_100/nodes.csv', header=None)\n",
    "nodes.columns = ['idx', 'product']\n",
    "\n",
    "product_array=np.array(list(nodes['product']))\n",
    "\n",
    "all_deltas = []\n",
    "vstars = []\n",
    "vstars_idx = []\n",
    "for f in os.listdir('jhu_package_100/deltas/'):\n",
    "    all_deltas.append(np.load('jhu_package_100/deltas/' + str(f)))\n",
    "    node_idx = int(str(f).split('.')[0])\n",
    "    vstars.append(product_array[node_idx])\n",
    "    vstars_idx.append(int(node_idx))\n",
    "    \n",
    "n, J = all_deltas[0].shape\n",
    "vstars = np.array(vstars)\n",
    "vstars_idx = np.array(vstars_idx)\n",
    "\n",
    "nodes_with_similar_products = np.unique(np.array(list(all_S_csv['SourceProduct'])))\n",
    "\n",
    "S_dict = {}\n",
    "for idx, row in all_S_csv.iterrows():\n",
    "    temp_prod = row['SourceProduct']\n",
    "    if temp_prod in list(S_dict.keys()):\n",
    "        S_dict[temp_prod].append(np.where(product_array == row['SimilarProduct'])[0][0])\n",
    "    else:\n",
    "        S_dict[temp_prod] = [np.where(product_array == row['SimilarProduct'])[0][0]]\n",
    "\n",
    "print(all_S_csv.head())\n",
    "print(S_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file C:\\Users\\hhelm\\gurobi.lic\n",
      "Academic license - for non-commercial use only\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "bad_keys = []\n",
    "nomination_lists = {}\n",
    "for key in S_dict:\n",
    "    try:\n",
    "        prod_idx = np.asarray(product_array == key).nonzero()[0][0]\n",
    "        deltas_idx = np.where(vstars == key)[0][0]\n",
    "\n",
    "        S_indices = S_dict[key]\n",
    "        dist_matrix = all_deltas[deltas_idx]\n",
    "        \n",
    "        alpha_hat, new_dists = optimal_distance(dist_matrix, S_indices)\n",
    "        \n",
    "        temp_nom_list = np.argsort(new_dists)\n",
    "        nomination_lists[key] = temp_nom_list\n",
    "    except:\n",
    "        bad_keys.append(key)\n",
    "    break\n",
    "print(bad_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv = []\n",
    "for key in S_dict:\n",
    "    if key not in bad_keys:\n",
    "        to_csv.append(product_array[nomination_lists[key]])\n",
    "df=pd.DataFrame(data=np.array(to_csv).T, index=np.concatenate((['V Star'], np.arange(1, n))))\n",
    "# df.to_csv('initial-nomination-lists-100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nomination_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSR",
   "language": "python",
   "name": "msr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
