{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "import numpy as np\n",
    "import graspy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_positions(n=50, d=2, acorn=None):\n",
    "    \"\"\"\n",
    "    A function to generate an adjacency matrix.\n",
    "    \n",
    "    Input\n",
    "    n - int\n",
    "        If P is None then n is the number of latent positions to randomly generate.\n",
    "    d - int\n",
    "        If P is None the d is the dimension of the latent positions.\n",
    "    acorn - int\n",
    "        Random seed.\n",
    "        \n",
    "    Return\n",
    "    X - np.array (shape=(n,d))\n",
    "        An array of uniformly distributed points in the positive unit sphere\n",
    "    \"\"\"\n",
    "    \n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    mvns = np.random.multivariate_normal(np.zeros(d), np.eye(d), size=n)\n",
    "\n",
    "    mvns = abs(mvns) / np.linalg.norm(mvns, axis=1)[:, None]\n",
    "\n",
    "    unis = np.random.uniform(size=n)**(1/d)\n",
    "    X = mvns * unis[:, None]\n",
    "                \n",
    "    return X\n",
    "        \n",
    "    \n",
    "def identity(X, ind):\n",
    "    _, d = X.shape\n",
    "    return np.eye(d)\n",
    "\n",
    "\n",
    "def generate_distance_matrix(A, embedding_functions, covariance_functions, ind=0,acorn=None):\n",
    "    \"\"\"\n",
    "    A function to generate a distance matrix given an adjacency matrix. The ith column of the\n",
    "    distance matrix is the Euclidean distance from the first node in the graph to the other\n",
    "    nodes in the ith embedding.\n",
    "    \n",
    "    Input\n",
    "    A - list of np.arrays (length=J) or np.array (shape=(n,d[j]))\n",
    "        Latent positions or adjacency matrix.\n",
    "    emebedding_functions - \n",
    "    \n",
    "    covariance_functions - \n",
    "    covariances - list of np.arrays (length=J, covariances[j].shape=(d[j],d[j]))\n",
    "        List of covariances to calculate the Mahalonobis distance between vectors in X.\n",
    "    acorn - int\n",
    "        Random seed.\n",
    "        \n",
    "    Return\n",
    "    dist_matrix - np.array (shape=(n, J))\n",
    "        Distance matrix where the ith column is the Euclidean distance from the first node in the graph\n",
    "        to all of the other nodes in the graph in the ith embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    if acorn is not None:\n",
    "        np.random.seed(acorn)\n",
    "        \n",
    "    n = A.shape[0]\n",
    "        \n",
    "    J = len(covariance_functions)\n",
    "            \n",
    "    dist_matrix = np.zeros((n, J))\n",
    "    \n",
    "    for j, embed in enumerate(embedding_functions):\n",
    "        temp_X = embed(A)\n",
    "            \n",
    "        if isinstance(covariance_functions[j], np.ndarray):\n",
    "            temp_cov = covariance_functions[j]\n",
    "        else:\n",
    "            temp_cov = covariance_functions[j](temp_X, ind)\n",
    "            \n",
    "        diffs = np.array([temp_X[ind] - temp_X[i] for i in range(n)])\n",
    "        dist_matrix[:, j] = np.sqrt(np.array([diffs[i].T @ temp_cov @ diffs[i] for i in range(n)]))\n",
    "       \n",
    "        if np.sum(dist_matrix[:, j] < 0) > 0:\n",
    "            print(\"i broke on distance %i\"%(j))\n",
    "    return dist_matrix  \n",
    "\n",
    "\n",
    "def generate_S_indices(dist_matrix, alpha, n_inds=1):\n",
    "    \"\"\"\n",
    "    A function to generate the nodes of interest.\n",
    "    \n",
    "    Input\n",
    "    dist_matrix - np.array (shape=(n,J))\n",
    "        Array containing the distances between the vertex of interest and the other n - 1\n",
    "        vertices. It is assumed that the vertex of interest is indexed by 0.\n",
    "    alpha - float or array-like\n",
    "        Coefficients of the distances to generate the ground truth. alpha can only be an int\n",
    "        if J == 2. If alpha is array-like then the sum of alpha must be 1.\n",
    "    n_inds - int or func\n",
    "        Number of vertices in the vertex set of interest. If n_inds is a function then the\n",
    "        ceiling of n_inds(n) is used.\n",
    "        \n",
    "    Return\n",
    "    S - np.array (length=n_inds)\n",
    "        A list of indices of length n_inds in range(1,n) corresponding to vertices of interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, J = dist_matrix.shape\n",
    "    \n",
    "    if isinstance(alpha, float):\n",
    "        assert J == 2\n",
    "        alpha = [alpha, 1-alpha]\n",
    "    \n",
    "    assert np.sum(alpha) == 1\n",
    "    \n",
    "    if not isinstance(n_inds, int):\n",
    "        n_inds = int(np.math.ceil(n_inds(n)))\n",
    "    \n",
    "    new_distances = np.average(dist_matrix, axis=1, weights=alpha)\n",
    "    \n",
    "    new_nearest_neighbors = np.argsort(new_distances)\n",
    "    \n",
    "    S = new_nearest_neighbors[1:n_inds+1]\n",
    "    \n",
    "    return S\n",
    "\n",
    "\n",
    "def optimal_distance(dist_matrix, S_indices, model_name=None, return_new_dists=True):\n",
    "    \"\"\"\n",
    "    A function to find the weights of optimal linear combination of distances.\n",
    "    \n",
    "    Input\n",
    "    dist_matrix - np.array (shape=(n, J))\n",
    "        Array containing the distances between the vertex of interest and the other n - 1\n",
    "        vertices. It is assumed that the vertex of interest is indexed by 0.\n",
    "    S_indices - array-like\n",
    "        Array-like containing the indices of the vertices that should be at the top of the\n",
    "        nomination list for the vertex of interest.\n",
    "        \n",
    "    Return\n",
    "    weights - np.array (length=J)\n",
    "        Array containing the coefficients for the optimal distance function.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, J = dist_matrix.shape\n",
    "    M = np.sum(abs(dist_matrix))\n",
    "    \n",
    "    S = len(S_indices)\n",
    "    Q_indices = np.array([i for i in range(1, n) if i not in S_indices])\n",
    "    Q = len(Q_indices)\n",
    "    \n",
    "    M = np.sum(abs(dist_matrix))\n",
    "    \n",
    "    if model_name is not None:\n",
    "        m = gp.Model(name='%s'%(model_name))\n",
    "    else:\n",
    "        m= gp.Model()\n",
    "        \n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    ind = m.addVars(Q, vtype=GRB.BINARY, name='ind')\n",
    "    m.setObjective(gp.quicksum(ind), GRB.MINIMIZE)\n",
    "\n",
    "    w = m.addVars(J, lb=0, ub=1, vtype=GRB.CONTINUOUS, name='w')\n",
    "    m.addConstr(w.sum() == 1)\n",
    "\n",
    "    # There's likely a more pythonic way to set up these constraints (in particular using m.addConstrs(..))\n",
    "    for s in S_indices:\n",
    "        temp_s = gp.tupledict([((i), dist_matrix[s, i]) for i in range(J)])\n",
    "        for i, q in enumerate(Q_indices):\n",
    "            temp_q = gp.tupledict([((i), dist_matrix[q, i]) for i in range(J)])\n",
    "            m.addConstr(w.prod(temp_s) <= w.prod(temp_q) + ind[i]*M)\n",
    "        \n",
    "    m.optimize()\n",
    "    \n",
    "    alpha_hat = np.array([i.X for i in list(w.values())])\n",
    "    \n",
    "    if model_name:\n",
    "        m.write('%s.ip'%(model_name))\n",
    "        \n",
    "    if return_new_dists:\n",
    "        return alpha_hat, np.average(dist_matrix, axis=1, weights=alpha_hat)\n",
    "    \n",
    "    return alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha: [0.1, 0.9]\n",
      "Estimated alpha: [0.08201382 0.91798618]\n",
      "\n",
      "\n",
      "S indices: [10 12 26 27 49]\n",
      "Five closest vertices to v star according to learned distance: [10 12 27 49 26]\n",
      "\n",
      "\n",
      "s star: 34\n",
      "Next two closest vertices to v star according to learned distance: [34 45]\n",
      "\n",
      "\n",
      "Seven closest vertices to v star according to ASE: [10 26 12 27 36 45  3]\n",
      "Seven closest vertices to v star according to LSE: [10 12 49 34 27 31 26]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "\n",
    "# Number of vertices, latent space dimension\n",
    "n, d = 50, 2\n",
    "\n",
    "# Latent positions\n",
    "X = generate_latent_positions(n=n, d=d)\n",
    "\n",
    "# Probability matrix\n",
    "P = X @ X.T\n",
    "\n",
    "# Embedding functions \n",
    "ASE = graspy.embed.AdjacencySpectralEmbed(n_components=d).fit_transform\n",
    "LSE = graspy.embed.LaplacianSpectralEmbed(n_components=d).fit_transform\n",
    "embedding_functions = [ASE, LSE]\n",
    "\n",
    "# Covariance functions used to calculate distances \n",
    "ASE_cov = identity\n",
    "LSE_cov = identity\n",
    "covariance_functions = [ASE_cov, LSE_cov]\n",
    "\n",
    "# Vertex of interest\n",
    "v_star = 0\n",
    "\n",
    "# Distance matrix from vertex of interest to all other vertices (including itself)\n",
    "dist_matrix = generate_distance_matrix(P, embedding_functions, covariance_functions, v_star)\n",
    "\n",
    "# Define \"true\" distance\n",
    "alpha = 0.1\n",
    "\n",
    "# Find the 6 closest vertices to v star as defined by the \"true\" distance\n",
    "S_indices = generate_S_indices(dist_matrix, alpha, n_inds=6)\n",
    "\n",
    "# Use the first five to learn the appropriate distance, the last to evaluate\n",
    "S_indices, s_star = S_indices[:-1], S_indices[-1]\n",
    "\n",
    "# Find weights, new distances \n",
    "alpha_hat, new_distance = optimal_distance(dist_matrix, S_indices)\n",
    "\n",
    "print(\"True alpha:\", [alpha, 1-alpha])\n",
    "print(\"Estimated alpha:\", alpha_hat)\n",
    "\n",
    "# The 5 things closest to v star in the new distance are the correct vertices\n",
    "print(\"\\n\")\n",
    "print(\"S indices:\", S_indices)\n",
    "print(\"Five closest vertices to v star according to learned distance:\", np.argsort(new_distance)[1:6])\n",
    "\n",
    "# s_star is the second closest vertex to v star in the new distance\n",
    "print(\"\\n\")\n",
    "print(\"s star:\", s_star)\n",
    "print(\"Next two closest vertices to v star according to learned distance:\", np.argsort(new_distance)[6:8])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Seven closest vertices to v star according to ASE:\", np.argsort(dist_matrix[:, 0])[1:8])\n",
    "print(\"Seven closest vertices to v star according to LSE:\", np.argsort(dist_matrix[:, 1])[1:8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSR",
   "language": "python",
   "name": "msr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
