{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_S_indices(dist_matrix, alpha, n_inds=1, return_new_dists=False, beta=0.5):\n",
    "    \"\"\"\n",
    "    A function to generate the nodes of interest.\n",
    "    \n",
    "    Input\n",
    "    dist_matrix - np.array (shape=(n,J))\n",
    "        Array containing the distances between the vertex of interest and the other n - 1\n",
    "        vertices. It is assumed that the vertex of interest is indexed by 0.\n",
    "    alpha - float or array-like\n",
    "        Coefficients of the distances to generate the ground truth. alpha can only be an int\n",
    "        if J == 2. If alpha is array-like then the sum of alpha must be 1.\n",
    "    n_inds - int or func\n",
    "        Number of vertices in the vertex set of interest. If n_inds is a function then the\n",
    "        ceiling of n_inds(n) is used.\n",
    "        \n",
    "    Return\n",
    "    S - np.array (length=n_inds)\n",
    "        A list of indices of length n_inds in range(1,n) corresponding to vertices of interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, J = dist_matrix.shape\n",
    "    \n",
    "    if isinstance(alpha, float):\n",
    "        if J == 2:\n",
    "            alpha = [alpha, 1-alpha]\n",
    "        elif J == 4:\n",
    "            alpha = np.array([beta*alpha, beta*(1-alpha), (1-beta)*alpha, (1-beta)*(1-alpha)])\n",
    "    \n",
    "    assert np.sum(alpha) == 1\n",
    "    \n",
    "    if not isinstance(n_inds, int):\n",
    "        n_inds = int(np.math.ceil(n_inds(n)))\n",
    "    \n",
    "    new_distances = np.average(dist_matrix, axis=1, weights=alpha)\n",
    "    \n",
    "    new_nearest_neighbors = np.argsort(new_distances)\n",
    "    \n",
    "    S = new_nearest_neighbors[1:n_inds+1]\n",
    "    \n",
    "    if return_new_dists:\n",
    "        return S, new_distances\n",
    "    else:\n",
    "        return S\n",
    "\n",
    "\n",
    "def optimal_distance(dist_matrix, S_indices, model_name=None, return_new_dists=True):\n",
    "    \"\"\"\n",
    "    A function to find the weights of optimal linear combination of distances.\n",
    "    \n",
    "    Input\n",
    "    dist_matrix - np.array (shape=(n, J))\n",
    "        Array containing the distances between the vertex of interest and the other n - 1\n",
    "        vertices. It is assumed that the vertex of interest is indexed by 0.\n",
    "    S_indices - array-like\n",
    "        Array-like containing the indices of the vertices that should be at the top of the\n",
    "        nomination list for the vertex of interest.\n",
    "        \n",
    "    Return\n",
    "    weights - np.array (length=J)\n",
    "        Array containing the coefficients for the optimal distance function.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, J = dist_matrix.shape\n",
    "    M = np.sum(abs(dist_matrix))\n",
    "    \n",
    "    S = len(S_indices)\n",
    "    Q_indices = np.array([i for i in range(1, n) if i not in S_indices])\n",
    "    Q = len(Q_indices)\n",
    "    \n",
    "    M = np.sum(abs(dist_matrix))\n",
    "    \n",
    "    if model_name is not None:\n",
    "        m = gp.Model(name='%s'%(model_name))\n",
    "    else:\n",
    "        m= gp.Model()\n",
    "        \n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    ind = m.addVars(Q, vtype=GRB.BINARY, name='ind')\n",
    "    m.setObjective(gp.quicksum(ind), GRB.MINIMIZE)\n",
    "\n",
    "    w = m.addVars(J, lb=0, ub=1, vtype=GRB.CONTINUOUS, name='w')\n",
    "    m.addConstr(w.sum() == 1)\n",
    "\n",
    "    # There's likely a more pythonic way to set up these constraints (in particular using m.addConstrs(..))\n",
    "    for s in S_indices:\n",
    "        temp_s = gp.tupledict([((i), dist_matrix[s, i]) for i in range(J)])\n",
    "        for i, q in enumerate(Q_indices):\n",
    "            temp_q = gp.tupledict([((i), dist_matrix[q, i]) for i in range(J)])\n",
    "            m.addConstr(w.prod(temp_s) <= w.prod(temp_q) + ind[i]*M)\n",
    "        \n",
    "    m.optimize()\n",
    "    \n",
    "    alpha_hat = np.array([i.X for i in list(w.values())])\n",
    "    \n",
    "    if model_name:\n",
    "        m.write('%s.ip'%(model_name))\n",
    "        \n",
    "    if return_new_dists:\n",
    "        return alpha_hat, np.average(dist_matrix, axis=1, weights=alpha_hat)\n",
    "    \n",
    "    return alpha_hat\n",
    "\n",
    "\n",
    "def rank_distance(true_ranks, estimated_ranks):\n",
    "    return np.mean(abs(true_ranks - estimated_ranks))\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(rank_list, inds):\n",
    "    \"\"\"\n",
    "    Calculates mean reciprocal rank given a rank list and set of indices of interest.\n",
    "    \n",
    "    Input\n",
    "    rank_list - array-like (length=n-1)\n",
    "        A ranked array-like of objects (assumed to be integers).\n",
    "    inds - array-like (length<=n-1)\n",
    "        A array-like of objects (assumed to be integers).\n",
    "        \n",
    "    Return\n",
    "    mrr - float\n",
    "        Mean reciprocal rank of the objects in inds.\n",
    "    \"\"\"\n",
    "        \n",
    "    ranks = np.array([np.where(rank_list == i)[0][0] for i in inds]) + 1\n",
    "    return np.mean(1/ranks)\n",
    "\n",
    "def mean_rank(rank_list, inds):\n",
    "    ranks = np.array([np.where(rank_list == i)[0][0] for i in inds]) + 1\n",
    "#     print(ranks)\n",
    "    return np.mean(ranks)\n",
    "\n",
    "\n",
    "def remove_S_indices(rank_lists, S_indices):\n",
    "    new_rank_lists = []\n",
    "    for i, r in enumerate(rank_lists):\n",
    "        idx = np.array([np.where(r == s)[0][0] for s in S_indices])\n",
    "        new_rank_lists.append(np.delete(r, idx))\n",
    "        \n",
    "    return new_rank_lists\n",
    "\n",
    "\n",
    "def average_rank(rank_lists, s_star_indices):\n",
    "    \n",
    "    average_ranks = np.zeros(len(rank_lists))\n",
    "    \n",
    "    for i, r in enumerate(rank_lists):\n",
    "        average_ranks[i] = np.mean(np.array([np.where(r == s)[0][0] for s in s_star_indices]))\n",
    "    \n",
    "    return average_ranks\n",
    "\n",
    "def plot_kde_differences(all_data, figsize=(8,6), h=1, num=1000, chance=None, suptitle=None, filename=None):\n",
    "    J, n = all_data.shape\n",
    "    colors = sns.color_palette('Set1', n_colors=J)\n",
    "    \n",
    "    min_ = min(np.array([min(data) for data in all_data]))\n",
    "    max_ = max(np.array([max(data) for data in all_data]))\n",
    "    \n",
    "    linspace = np.linspace(min_ - h, max_ + h, num)\n",
    "    \n",
    "    fig, ax = plt.subplots(J, J, sharex=True, sharey=True)\n",
    "    \n",
    "#     ax[0,0].set_ylim(-0.2, 0.2)\n",
    "    \n",
    "    for i, di in enumerate(all_data):\n",
    "        for j, dj in enumerate(all_data):\n",
    "            if i == j:\n",
    "                temp_kdei = gaussian_kde(di)\n",
    "                ax[i,i].plot(linspace, temp_kdei.pdf(linspace), c=colors[-i-1])\n",
    "#                 sns.kdeplot(di, ax=ax[i,j], c=c[i])\n",
    "                if chance:\n",
    "                    ax[i,i].axvline(x=chance, c='k', ls='--', lw=1)\n",
    "            else:\n",
    "                temp_kdei = gaussian_kde(di)\n",
    "                temp_kdej = gaussian_kde(dj)\n",
    "                \n",
    "                ax[i,j].plot(linspace, temp_kdei.pdf(linspace) - temp_kdej.pdf(linspace), ls=\"--\")\n",
    "            ax[i,j].axhline(y=0, c='k', lw=1)\n",
    "            \n",
    "            \n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle)\n",
    "        \n",
    "    if filename:\n",
    "        plt.savefig(filename)\n",
    "        \n",
    "def estimate_chance_mrr(n, nZ, nmc=10000):\n",
    "    mrrs = np.zeros(nmc)\n",
    "    \n",
    "    for i in range(nmc):\n",
    "        temp = np.random.choice(n, nZ, replace=False) + 1\n",
    "        mrrs[i] = np.mean(1 / temp)\n",
    "        \n",
    "    return np.mean(mrrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(rank_list, inds):\n",
    "    \"\"\"\n",
    "    A function to compute the mean reciprocal rank of a set of indices.\n",
    "    \n",
    "    Input\n",
    "    rank_list - array of ints\n",
    "        Array containing the ranked objects indices. rank_list[i] is original index the ith ranked object. \n",
    "    inds - array-like of ints\n",
    "        Indices of objects for which you want their ranking, per rank_list.\n",
    "        \n",
    "    Return\n",
    "    The mean reciprocal rank of the objects in inds.\n",
    "    \"\"\"\n",
    "    ranks = np.array([np.where(rank_list == i)[0][0] for i in inds]) + 1\n",
    "    \n",
    "    return np.mean(1 / ranks)\n",
    "\n",
    "def find_best_vertices(dist_matrix, S_indices):\n",
    "    \"\"\"\n",
    "    A function to find the best individual metrics.\n",
    "    \n",
    "    Input\n",
    "    dist_matrix - array (shape=(n,J))\n",
    "        An array containing J distances from an object of interest to n-1 other objects.\n",
    "    S_indices - array-like\n",
    "        The set of vertices known to be similar to an object of interest.\n",
    "        \n",
    "    Returns\n",
    "    The metrics that minimize the maximum rank of an element of S and the corresponding\n",
    "        objective function value.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n, J = dist_matrix.shape\n",
    "    \n",
    "    argmin = []\n",
    "    min_ = n\n",
    "    \n",
    "    for j in range(J):\n",
    "        dist = dist_matrix[:, j]\n",
    "        rank_list = np.argsort(dist)\n",
    "        \n",
    "        S_ranks = np.zeros(len(S_indices), dtype='int')\n",
    "        for i, s in enumerate(S_indices):\n",
    "            S_ranks[i] = np.where(rank_list == s)[0][0]\n",
    "                    \n",
    "        obj_func_value = len(np.delete(np.arange(max(S_ranks)+1), S_ranks)) - 1\n",
    "        if obj_func_value == min_:\n",
    "            argmin.append(j)\n",
    "        elif obj_func_value < min_:\n",
    "            argmin = [j]\n",
    "            min_ = obj_func_value\n",
    "    \n",
    "    return np.array(argmin), min_\n",
    "\n",
    "def evaluate_best_vertices(dist_matrix, vertices, s_star):\n",
    "    \"\"\"\n",
    "    A function to evaluate a set of individual metrics.\n",
    "    \n",
    "    Input\n",
    "    dist_matrix - array (shape=(n,J))\n",
    "        An array containing J distances from an object of interest to n-1 other objects.\n",
    "    vertices - array-like\n",
    "        The set of individual metrics to evaluate.\n",
    "    s_star - array-like\n",
    "        The set of indices for which the individual metrics are evaluated.\n",
    "        \n",
    "    \n",
    "    Return\n",
    "    ranks - np.array\n",
    "        The rankings of the elements of s_star.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, _ = dist_matrix.shape\n",
    "    J_ = len(vertices)\n",
    "    \n",
    "    ranks = np.zeros(len(vertices))\n",
    "    \n",
    "    if len(s_star) > 1:\n",
    "        raise ValueError('not implemented')\n",
    "        \n",
    "    for j, v in enumerate(vertices):\n",
    "        temp_ranks = np.argsort(dist_matrix[:, j])\n",
    "        ranks[j] = np.array([np.where(temp_ranks == s)[0][0] for s in s_star])\n",
    "    \n",
    "    return ranks\n",
    "\n",
    "def remove_S_indices(rank_lists, S_indices):\n",
    "    \"\"\"\n",
    "    A function to remove elements from a rank-list.\n",
    "    \n",
    "    Input\n",
    "    rank_lists - list\n",
    "        A list of arrays.\n",
    "    S_indices - array-like\n",
    "        The set of objects to be removed.\n",
    "        \n",
    "    Return\n",
    "    new_rank_lists - list\n",
    "        A list of arrays with S_indices removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_rank_lists = []\n",
    "    for i, r in enumerate(rank_lists):\n",
    "        idx = np.array([np.where(r == s)[0][0] for s in S_indices])\n",
    "        new_rank_lists.append(np.delete(r, idx))\n",
    "        \n",
    "    return new_rank_lists\n",
    "        \n",
    "\n",
    "def get_unique_indices(all_deltas, indices=np.array([0]), threshold=0):\n",
    "    \"\"\"\n",
    "    A function to find the \"unique\" metrics.\n",
    "    \n",
    "    Input\n",
    "    all_deltas - list\n",
    "        A list of matrices of shape (n,J).\n",
    "    indices - array-like\n",
    "        A list containing the indices of the metrics that we know we want to use.\n",
    "    threshold - float\n",
    "        \"Unique\"ness threshold.\n",
    "        \n",
    "    Return\n",
    "    An array of unique metric indices.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, J = all_deltas[0].shape\n",
    "    \n",
    "    triu=np.triu_indices(J, k=1)\n",
    "    \n",
    "    for i, delta in enumerate(all_deltas):\n",
    "        temp_diff = pairwise_distances(delta.T)\n",
    "        candidates = np.array([i for i in range(J) if i not in indices])\n",
    "        \n",
    "        new_indices = []\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        while j < len(candidates):\n",
    "            candidates[j], temp_diff[:, indices]\n",
    "            if np.sum(temp_diff[candidates[j], indices] < threshold) == 1:\n",
    "                indices = np.concatenate((indices, [candidates[j]]))\n",
    "                \n",
    "            j+=1\n",
    "                \n",
    "    return np.sort(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = 2965, 1\n",
    "max_d=11\n",
    "d_idx = np.concatenate([np.arange(d), np.arange(max_d, max_d+d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2965, 2965)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_csv = pd.read_csv('data/connectome-g5-LSE-unnorm/connectome-g1-LSE-n2965-dhat11x2-unnorm.csv')\n",
    "g1=np.array(g1_csv)[:, 1:][:, d_idx]\n",
    "\n",
    "g2_csv = pd.read_csv('data/connectome-g5-LSE-unnorm/connectome-g2-LSE-n2965-dhat11x2-unnorm.csv')\n",
    "g2=np.array(g2_csv)[:, 1:][:, d_idx]\n",
    "\n",
    "g3_csv = pd.read_csv('data/connectome-g5-LSE-unnorm/connectome-g3-LSE-n2965-dhat11x2-unnorm.csv')\n",
    "g3=np.array(g3_csv)[:, 1:][:, d_idx]\n",
    "\n",
    "g4_csv = pd.read_csv('data/connectome-g5-LSE-unnorm/connectome-g4-LSE-n2965-dhat11x2-unnorm.csv')\n",
    "g4=np.array(g4_csv)[:, 1:][:, d_idx]\n",
    "\n",
    "g5_csv = pd.read_csv('data/connectome-g5-LSE-unnorm/connectome-g5-LSE-n2965-dhat11x2-unnorm.csv')\n",
    "g5=np.array(g5_csv)[:, 1:][:, d_idx]\n",
    "\n",
    "all_gs = [g1, g2, g3, g4, g5]\n",
    "all_dist_matrices = np.array([pairwise_distances(g) for g in all_gs])\n",
    "\n",
    "all_dist_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('data/connectome-meta-n2965x16.csv')\n",
    "mbins = np.arange(n)[np.array(meta['Class4'] == 'MBIN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorn=3\n",
    "np.random.seed(acorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5f84a854e649f280902b066258852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file C:\\Users\\hhelm\\gurobi.lic\n",
      "Academic license - for non-commercial use only\n",
      "[0.81325427 0.03632067 0.04557897 0.10484609]\n",
      "[0.05864708 0.         0.91877993 0.02257299]\n",
      "[0.7562233  0.         0.20823379 0.03554292]\n",
      "[0.18930956 0.01523898 0.20096451 0.59448695]\n",
      "[0.54590545 0.43566823 0.01842632 0.        ]\n",
      "[1. 0. 0. 0.]\n",
      "[0.01753629 0.01099404 0.97146967 0.        ]\n",
      "[0.73079064 0.07223472 0.19697465 0.        ]\n",
      "[0.02263292 0.00594619 0.87804972 0.09337116]\n",
      "[0.38460293 0.16108045 0.         0.45431662]\n",
      "[0.03672006 0.04837096 0.91490898 0.        ]\n",
      "[0.00213988 0.0042851  0.         0.99357502]\n",
      "[0.01500203 0.00439411 0.98060386 0.        ]\n",
      "[0.08325974 0.04875925 0.84224898 0.02573203]\n",
      "[0. 0. 1. 0.]\n",
      "[0.02401283 0.0021924  0.97379477 0.        ]\n",
      "[0.48612937 0.50944982 0.0044208  0.        ]\n",
      "[1. 0. 0. 0.]\n",
      "[0.         0.         0.98825975 0.01174025]\n",
      "[0.         0.49775883 0.38835013 0.11389104]\n",
      "[0.41474001 0.06163101 0.52362899 0.        ]\n",
      "[0.48516416 0.10247649 0.         0.41235935]\n",
      "[0.         0.         0.91429037 0.08570963]\n",
      "[0.         0.37703161 0.         0.62296839]\n",
      "[0.         0.03188632 0.01232428 0.9557894 ]\n",
      "[1. 0. 0. 0.]\n",
      "[7.59764053e-01 5.27953483e-04 2.39095972e-01 6.12021644e-04]\n",
      "[0.12297653 0.03343463 0.84358884 0.        ]\n",
      "[1. 0. 0. 0.]\n",
      "[0.57613328 0.07938948 0.34447723 0.        ]\n",
      "[0.18266372 0.07094912 0.         0.74638715]\n",
      "[0.13711873 0.00891837 0.73922595 0.11473695]\n",
      "[0.13461562 0.07049626 0.79488812 0.        ]\n",
      "[0.0345131  0.24258373 0.01538185 0.70752132]\n",
      "[0.29095054 0.19680469 0.51224477 0.        ]\n",
      "[0.11395869 0.09837664 0.         0.78766467]\n",
      "[0.08794828 0.27287578 0.5916558  0.04752014]\n",
      "[0.29153526 0.02980034 0.6786644  0.        ]\n",
      "[1. 0. 0. 0.]\n",
      "[0.         0.         0.94237137 0.05762863]\n",
      "[0.08813898 0.         0.         0.91186102]\n",
      "[0.1587555 0.        0.        0.8412445]\n",
      "[0.39857248 0.         0.60142752 0.        ]\n",
      "[0. 0. 0. 1.]\n",
      "[0.00000000e+00 2.07299455e-16 0.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "indices=np.array([0,1,2,3])\n",
    "\n",
    "S_sizes = np.arange(1, len(mbins))\n",
    "mrrs = np.zeros((len(S_sizes),3,len(mbins)))\n",
    "\n",
    "for j, S_size in enumerate(tqdm(S_sizes)):\n",
    "    total=0\n",
    "    for i, vstar in enumerate(mbins):\n",
    "        S_star = np.delete(mbins, i)\n",
    "        S_temp = np.random.choice(S_star, S_size, replace=False)\n",
    "        S_star_minus_S = np.array([s for s in S_star if s not in S_temp])\n",
    "\n",
    "        dist_matrix = all_dist_matrices[indices, vstar].T\n",
    "\n",
    "        temp_best, temp_min = find_best_vertices(dist_matrix, S_temp)\n",
    "        temp_mrrs = np.zeros(len(temp_best))\n",
    "#         print(\"best vertices:\", temp_best)\n",
    "#         print(\"obj func:\", temp_min)\n",
    "        for k, vertex in enumerate(temp_best):\n",
    "            temp_vertex = remove_S_indices([np.argsort(dist_matrix[:, vertex])[1:]], S_temp)[0]\n",
    "            temp_mrrs[k] = mean_reciprocal_rank(temp_vertex, S_star_minus_S)\n",
    "\n",
    "        if temp_min > 0:\n",
    "            alpha_hat, new_dists = optimal_distance(dist_matrix, S_temp)\n",
    "            print(alpha_hat)\n",
    "    #         alpha_hats_LOO[i][j] = alpha_hat\n",
    "        else:\n",
    "            alpha_hat = np.zeros(len(indices))\n",
    "            alpha_hat[temp_best[0]] = 1\n",
    "\n",
    "        if np.sum(alpha_hat == 1) > 0:\n",
    "            mrrs[j][0][total] = np.mean(temp_mrrs)\n",
    "        else:\n",
    "            temp_IP = remove_S_indices([np.argsort(new_dists)[1:]], S_temp)[0]\n",
    "            mrrs[j][0][total] = mean_reciprocal_rank(temp_IP, S_star_minus_S)\n",
    "\n",
    "        mrrs[j][1][total] = np.mean(temp_mrrs)\n",
    "\n",
    "        sum_distances = all_dist_matrices[-1]\n",
    "        sum_rankings = remove_S_indices([np.argsort(sum_distances[:, vertex])[1:]], S_temp)[0]\n",
    "        mrrs[j][2][total] = mean_reciprocal_rank(sum_rankings, S_star_minus_S)\n",
    "\n",
    "#         print(total, \"ILP:\", mrrs[0][total], \"best vertex:\", mrrs[1][total], \"sum:\", mrrs[2][total])\n",
    "\n",
    "        pickle.dump(mrrs, open('mrrs_directed_expected_mrr_lse_sum_vs_four_acorn%i.pkl'%(acorn), 'wb'))\n",
    "        total+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSR",
   "language": "python",
   "name": "msr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
